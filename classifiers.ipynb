{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import copy\n",
    "from tabulate import tabulate\n",
    "import random\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MySimpleLinearRegressor, MyNaiveBayesClassifier, MyDecisionTreeClassifier, MyRandomForestClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_fname = os.path.join(\"data\",\"clean_fire_data.csv\")\n",
    "wildfire_table = MyPyTable()\n",
    "wildfire_table.load_from_file(wildfire_fname)\n",
    "\n",
    "fire_date = wildfire_table.get_column(\"date\")\n",
    "county = wildfire_table.get_column(\"county\")\n",
    "acres = wildfire_table.get_column(\"acres\")\n",
    "cause = wildfire_table.get_column(\"cause\")\n",
    "lat = wildfire_table.get_column(\"lat\")\n",
    "lng = wildfire_table.get_column(\"lon\")\n",
    "binlat = wildfire_table.get_column(\"binlat\")\n",
    "binlon = wildfire_table.get_column(\"binlon\")\n",
    "binacres = wildfire_table.get_column(\"binacres\")\n",
    "\n",
    "wildfire_X = [[fire_date[i], county[i], cause[i], binlat[i], binlon[i]] for i in range(len(fire_date))]\n",
    "wildfire_y = [x for x in binacres]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3737\n{'Aug', 'May', 'Dec', 'Sep', 'Jul', 'Jan', 'Nov', 'Oct', 'Jun', 'Apr', 'Feb', 'Mar'}\n{'No Data', 'Cowlitz', 'Walla Walla', 'Franklin', 'Columbia', 'Spokane', 'King', 'Clallam', 'Ferry', 'Klickitat', 'Wahkiakum', 'Lincoln', 'Whatcom', 'Grays Harbor', 'Yakima', 'Adams', 'Chelan', 'Kittitas', 'Mason', 'Island', 'Asotin', 'Lewis', 'Skamania', 'Benton', 'Skagit', 'Pend Oreille', 'Whitman', 'Pierce', 'Pacific', 'Okanogan', 'Clark', 'Garfield', 'Grant', 'San Juan', 'Douglas', 'Kitsap', 'Stevens', 'Thurston', 'Snohomish', 'Jefferson'}\n{'Lightning', 'Undetermined', 'Miscellaneou', 'Debris Burn', 'Recreation', 'None', 'Smoker', 'Under Invest', 'Logging', 'Arson', 'Railroad', 'Children'}\n{1.0, 2.0, 3.0, 4.0}\n{1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0}\n{2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}\n"
     ]
    }
   ],
   "source": [
    "print(len(wildfire_X))\n",
    "print(set(fire_date))\n",
    "print(set(county))\n",
    "print(set(cause))\n",
    "print(set(binlat))\n",
    "print(set(binlon))\n",
    "print(set(binacres))"
   ]
  },
  {
   "source": [
    "## Finding the best tree\n",
    "\n",
    "The below code tries to find a better 'best tree' than previously found\n",
    "so far the best tree that we have found is \n",
    "\n",
    "F: 1 N: 5 M: 4 Accuracy: 0.433"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = myevaluation.train_test_split(copy.deepcopy(wildfire_X), copy.deepcopy(wildfire_y), test_size=1000)\n",
    "\n",
    "best_trees = []\n",
    "max_accuracy = .433\n",
    "\n",
    "for i in range(20):\n",
    "    F = random.randint(1,5)\n",
    "    N = random.randint(1,30)\n",
    "    M = random.randint(1,N)\n",
    "\n",
    "    rf = MyRandomForestClassifier()\n",
    "    rf.fit(wildfire_X, wildfire_y, F=1, N=5, M=4)\n",
    "\n",
    "    predictions = []\n",
    "    for i, x in enumerate(X_test):\n",
    "        prediction = rf.predict([x])\n",
    "        # print(prediction, y_test[i])\n",
    "        # print(prediction)\n",
    "        predictions.append(int(prediction[0] == y_test[i]))\n",
    "    if sum(predictions)/len(predictions) > max_accuracy:\n",
    "        print(\"F:\", F, \"N:\", N, \"M:\", M, \"Accuracy:\", sum(predictions)/len(predictions))\n",
    "        f = open(\"best_tree.txt\", \"w\")\n",
    "        f.write(str(rf.trees))\n",
    "        f.close()\n",
    "        max_accuracy = sum(predictions)/len(predictions)\n",
    "        best_trees = rf.trees\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "source": [
    "## Testing of best tree\n",
    "\n",
    "next we test the best tree with some random samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "if best_trees == []:\n",
    "    with open(\"best_tree.txt\", \"r\") as data:\n",
    "        best_trees = ast.literal_eval(data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "999/999    \n",
      "Random Forest: accuracy = 0.42 error rate = 0.5800000000000001\n"
     ]
    }
   ],
   "source": [
    "test_size = 1000\n",
    "\n",
    "X_train, X_test, y_train, y_test = myevaluation.train_test_split(copy.deepcopy(wildfire_X), copy.deepcopy(wildfire_y), test_size=test_size, shuffle=True)\n",
    "\n",
    "rf = MyRandomForestClassifier()\n",
    "rf.trees = copy.deepcopy(best_trees)\n",
    "predictions = []\n",
    "for i, x in enumerate(X_test):\n",
    "    sys.stdout.write(\"\\r\" + str(i) + \"/\" + str(len(X_test) -1) + \"    \")\n",
    "    sys.stdout.flush()\n",
    "    prediction = rf.predict([x])\n",
    "    predictions.append(prediction[0])\n",
    "\n",
    "print()\n",
    "acc = round(sum([int(x==y) for x,y in zip(predictions, y_test)])/len(predictions), 2)\n",
    "print(\"Random Forest: accuracy = \" + str(acc) + \" error rate = \" + str(1-acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forests Results\n  acres    1.0    2.0    3.0    4.0    5.0    6.0    7.0    8.0    9.0    total    recognition %\n-------  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------  ---------------\n      1      0      0      0      0      0      0      0      0      0        0             0\n      2      0     83     59      9     12      4      2      1      0      170            48.82\n      3      0    200    319     85    111     37     13     10      7      782            40.79\n      4      0      2      6      5      2      1      2      0      0       18            27.78\n      5      0      2      5      1      4      0      2      0      0       14            28.57\n      6      0      0      4      2      2      3      0      0      2       13            23.08\n      7      0      0      0      0      0      1      2      0      0        3            66.67\n      8      0      0      0      0      0      0      0      0      0        0             0\n      9      0      0      0      0      0      0      0      0      0        0             0\n"
     ]
    }
   ],
   "source": [
    "headers = [\"acres\", \"1.0\", \"2.0\", \"3.0\", \"4.0\", \"5.0\", \"6.0\", \"7.0\", \"8.0\", \"9.0\", \"total\", \"recognition %\"]\n",
    "mat = myevaluation.confusion_matrix(predictions, y_test, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])\n",
    "myutils.build_confusion_matrix(mat)\n",
    "print(\"Random Forests Results\")\n",
    "print(tabulate(mat, headers))"
   ]
  },
  {
   "source": [
    "## KNN\n",
    "The code below tests intstances of the dataset using the the knn classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "999/999    \n",
      "KNN: accuracy = 0.31 error rate = 0.69\n"
     ]
    }
   ],
   "source": [
    "test_size = 1000\n",
    "\n",
    "X_train, X_test, y_train, y_test = myevaluation.train_test_split(copy.deepcopy(wildfire_X), copy.deepcopy(wildfire_y), test_size=test_size, shuffle=True)\n",
    "\n",
    "nb = MyKNeighborsClassifier()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = []\n",
    "for i, x in enumerate(X_test):\n",
    "    sys.stdout.write(\"\\r\" + str(i) + \"/\" + str(len(X_test) -1) + \"    \")\n",
    "    sys.stdout.flush()\n",
    "    prediction = nb.predict([x])\n",
    "    predictions.append(prediction[0])\n",
    "\n",
    "print()\n",
    "acc = round(sum([int(x==y) for x,y in zip(predictions, y_test)])/len(predictions), 2)\n",
    "print(\"KNN: accuracy = \" + str(acc) + \" error rate = \" + str(1-acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN Results\n  acres    1.0    2.0    3.0    4.0    5.0    6.0    7.0    8.0    9.0    total    recognition %\n-------  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------  ---------------\n      1      0      0      0      0      0      0      0      0      0        0             0\n      2      0    104    128     22     34     14      8      3      2      315            33.02\n      3      0    137    171     44     40     19      5      3      1      420            40.71\n      4      0     21     22      5      3      2      0      0      0       53             9.43\n      5      0     26     47     12     21      4      3      1      0      114            18.42\n      6      0     10     23      7     17      8      2      2      0       69            11.59\n      7      0      3      6      2      6      4      2      0      0       23             8.7\n      8      0      0      0      0      1      0      0      0      0        1             0\n      9      0      0      2      1      1      1      0      0      0        5             0\n"
     ]
    }
   ],
   "source": [
    "headers = [\"acres\", \"1.0\", \"2.0\", \"3.0\", \"4.0\", \"5.0\", \"6.0\", \"7.0\", \"8.0\", \"9.0\", \"total\", \"recognition %\"]\n",
    "mat = myevaluation.confusion_matrix(predictions, y_test, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])\n",
    "myutils.build_confusion_matrix(mat)\n",
    "print(\"KNN Results\")\n",
    "print(tabulate(mat, headers))"
   ]
  },
  {
   "source": [
    "## Naive Bayes\n",
    "\n",
    "The code below tests the acuracy of the dataset using the Naive Bayes classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "999/999    \n",
      "Naive Bayes: accuracy = 0.36 error rate = 0.64\n"
     ]
    }
   ],
   "source": [
    "test_size = 1000\n",
    "\n",
    "X_train, X_test, y_train, y_test = myevaluation.train_test_split(copy.deepcopy(wildfire_X), copy.deepcopy(wildfire_y), test_size=test_size, shuffle=True)\n",
    "\n",
    "nb = MyNaiveBayesClassifier()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = []\n",
    "for i, x in enumerate(X_test):\n",
    "    sys.stdout.write(\"\\r\" + str(i) + \"/\" + str(len(X_test) -1) + \"    \")\n",
    "    sys.stdout.flush()\n",
    "    prediction = nb.predict([x])\n",
    "    predictions.append(prediction[0])\n",
    "\n",
    "print()\n",
    "acc = round(sum([int(x==y) for x,y in zip(predictions, y_test)])/len(predictions), 2)\n",
    "print(\"Naive Bayes: accuracy = \" + str(acc) + \" error rate = \" + str(1-acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN Results\n  acres    1.0    2.0    3.0    4.0    5.0    6.0    7.0    8.0    9.0    total    recognition %\n-------  -----  -----  -----  -----  -----  -----  -----  -----  -----  -------  ---------------\n      1      0      0      0      0      0      0      0      0      0        0             0\n      2      0    127    120     16     26      5      1      1      0      296            42.91\n      3      0    140    200     49     64     21      6      6      0      486            41.15\n      4      0      0      2      0      3      0      0      0      0        5             0\n      5      0     22     34      9     22      7      8      4      2      108            20.37\n      6      0     11     13      8      4      5      1      2      1       45            11.11\n      7      0      2      5      1      1      2      2      0      0       13            15.38\n      8      0      1      3      1      1      2      3      1      1       13             7.69\n      9      0      6     12      3      8      3      2      0      0       34             0\n"
     ]
    }
   ],
   "source": [
    "headers = [\"acres\", \"1.0\", \"2.0\", \"3.0\", \"4.0\", \"5.0\", \"6.0\", \"7.0\", \"8.0\", \"9.0\", \"total\", \"recognition %\"]\n",
    "mat = myevaluation.confusion_matrix(predictions, y_test, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])\n",
    "myutils.build_confusion_matrix(mat)\n",
    "print(\"KNN Results\")\n",
    "print(tabulate(mat, headers))"
   ]
  }
 ]
}