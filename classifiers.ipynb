{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import copy\n",
    "from tabulate import tabulate\n",
    "import random\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MySimpleLinearRegressor, MyNaiveBayesClassifier, MyDecisionTreeClassifier, MyRandomForestClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_fname = os.path.join(\"data\",\"clean_fire_data.csv\")\n",
    "wildfire_table = MyPyTable()\n",
    "wildfire_table.load_from_file(wildfire_fname)\n",
    "\n",
    "fire_date = wildfire_table.get_column(\"date\")\n",
    "county = wildfire_table.get_column(\"county\")\n",
    "acres = wildfire_table.get_column(\"acres\")\n",
    "cause = wildfire_table.get_column(\"cause\")\n",
    "lat = wildfire_table.get_column(\"lat\")\n",
    "lng = wildfire_table.get_column(\"lon\")\n",
    "binlat = wildfire_table.get_column(\"binlat\")\n",
    "binlon = wildfire_table.get_column(\"binlon\")\n",
    "binacres = wildfire_table.get_column(\"binacres\")\n",
    "\n",
    "wildfire_X = [[fire_date[i], county[i], cause[i], binlat[i], binlon[i]] for i in range(len(fire_date))]\n",
    "wildfire_y = [x for x in binacres]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3737\n{'Nov', 'Sep', 'Mar', 'Aug', 'Oct', 'May', 'Jan', 'Apr', 'Jun', 'Dec', 'Jul', 'Feb'}\n{'KING', 'PIERCE', 'KITTITAS', 'KITSAP', 'PEND OREILLE', 'SNOHOMISH', 'YAKIMA', 'NO DATA', 'WALLA WALLA', 'STEVENS', 'CHELAN', 'CLALLAM', 'KLICKITAT', 'ADAMS', 'WHATCOM', 'SPOKANE', 'ISLAND', 'GARFIELD', 'SKAGIT', 'GRANT', 'MASON', 'WAHKIAKUM', 'FERRY', 'WHITMAN', 'THURSTON', 'LINCOLN', 'SKAMANIA', 'FRANKLIN', 'BENTON', 'GRAYS HARBOR', 'COLUMBIA', 'JEFFERSON', 'COWLITZ', 'SAN JUAN', 'ASOTIN', 'CLARK', 'LEWIS', 'DOUGLAS', 'OKANOGAN', 'PACIFIC'}\n{'Lightning', 'Arson', 'Recreation', 'Smoker', 'Railroad', 'Miscellaneou', 'Under Invest', 'Undetermined', 'Debris Burn', 'Logging', 'None', 'Children'}\n{1.0, 2.0, 3.0, 4.0}\n{1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0}\n{2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}\n"
     ]
    }
   ],
   "source": [
    "print(len(wildfire_X))\n",
    "print(set(fire_date))\n",
    "print(set(county))\n",
    "print(set(cause))\n",
    "print(set(binlat))\n",
    "print(set(binlon))\n",
    "print(set(binacres))"
   ]
  },
  {
   "source": [
    "## Finding the best tree\n",
    "\n",
    "The below code tries to find a better 'best tree' than previously found\n",
    "so far the best tree that we have found is \n",
    "\n",
    "F: 1 N: 5 M: 4 Accuracy: 0.425"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = myevaluation.train_test_split(copy.deepcopy(wildfire_X), copy.deepcopy(wildfire_y), test_size=1000)\n",
    "\n",
    "best_trees = []\n",
    "max_accuracy = .425\n",
    "\n",
    "for i in range(20):\n",
    "    F = random.randint(1,5)\n",
    "    N = random.randint(1,30)\n",
    "    M = random.randint(1,N)\n",
    "\n",
    "    rf = MyRandomForestClassifier()\n",
    "    rf.fit(wildfire_X, wildfire_y, F=F, N=N, M=M)\n",
    "\n",
    "    predictions = []\n",
    "    for i, x in enumerate(X_test):\n",
    "        prediction = rf.predict([x])\n",
    "        # print(prediction, y_test[i])\n",
    "        # print(prediction)\n",
    "        predictions.append(int(prediction[0] == y_test[i]))\n",
    "    if sum(predictions)/len(predictions) > max_accuracy:\n",
    "        print(\"F:\", F, \"N:\", N, \"M:\", M, \"Accuracy:\", sum(predictions)/len(predictions))\n",
    "        f = open(\"best_tree.txt\", \"w\")\n",
    "        f.write(str(rf.trees))\n",
    "        f.close()\n",
    "        max_accuracy = sum(predictions)/len(predictions)\n",
    "        best_trees = rf.trees\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "source": [
    "## Testing of best tree\n",
    "\n",
    "next we test the best tree with some random samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "999/999    \n",
      "Random Forest: accuracy = 0.4 error rate = 0.6\n"
     ]
    }
   ],
   "source": [
    "test_size = 1000\n",
    "\n",
    "X_train, X_test, y_train, y_test = myevaluation.train_test_split(copy.deepcopy(wildfire_X), copy.deepcopy(wildfire_y), test_size=test_size, shuffle=True)\n",
    "\n",
    "rf = MyRandomForestClassifier()\n",
    "rf.trees = copy.deepcopy(best_trees)\n",
    "predictions = []\n",
    "for i, x in enumerate(X_test):\n",
    "    sys.stdout.write(\"\\r\" + str(i) + \"/\" + str(len(X_test) -1) + \"    \")\n",
    "    sys.stdout.flush()\n",
    "    prediction = rf.predict([x])\n",
    "    predictions.append(prediction[0])\n",
    "\n",
    "print()\n",
    "acc = round(sum([int(x==y) for x,y in zip(predictions, y_test)])/len(predictions), 2)\n",
    "print(\"Random Forest: accuracy = \" + str(acc) + \" error rate = \" + str(1-acc))\n"
   ]
  },
  {
   "source": [
    "## KNN\n",
    "The code below tests intstances of the dataset using the the knn classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "999/999    \n",
      "KNN: accuracy = 0.33 error rate = 0.6699999999999999\n"
     ]
    }
   ],
   "source": [
    "test_size = 1000\n",
    "\n",
    "X_train, X_test, y_train, y_test = myevaluation.train_test_split(copy.deepcopy(wildfire_X), copy.deepcopy(wildfire_y), test_size=test_size, shuffle=True)\n",
    "\n",
    "nb = MyKNeighborsClassifier()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = []\n",
    "for i, x in enumerate(X_test):\n",
    "    sys.stdout.write(\"\\r\" + str(i) + \"/\" + str(len(X_test) -1) + \"    \")\n",
    "    sys.stdout.flush()\n",
    "    prediction = nb.predict([x])\n",
    "    predictions.append(prediction[0])\n",
    "\n",
    "print()\n",
    "acc = round(sum([int(x==y) for x,y in zip(predictions, y_test)])/len(predictions), 2)\n",
    "print(\"KNN: accuracy = \" + str(acc) + \" error rate = \" + str(1-acc))"
   ]
  },
  {
   "source": [
    "## Naive Bayes\n",
    "\n",
    "The code below tests the acuracy of the dataset using the Naive Bayes classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "999/999    \n",
      "Naive Bayes: accuracy = 0.34 error rate = 0.6599999999999999\n"
     ]
    }
   ],
   "source": [
    "test_size = 1000\n",
    "\n",
    "X_train, X_test, y_train, y_test = myevaluation.train_test_split(copy.deepcopy(wildfire_X), copy.deepcopy(wildfire_y), test_size=test_size, shuffle=True)\n",
    "\n",
    "nb = MyNaiveBayesClassifier()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = []\n",
    "for i, x in enumerate(X_test):\n",
    "    sys.stdout.write(\"\\r\" + str(i) + \"/\" + str(len(X_test) -1) + \"    \")\n",
    "    sys.stdout.flush()\n",
    "    prediction = nb.predict([x])\n",
    "    predictions.append(prediction[0])\n",
    "\n",
    "print()\n",
    "acc = round(sum([int(x==y) for x,y in zip(predictions, y_test)])/len(predictions), 2)\n",
    "print(\"Naive Bayes: accuracy = \" + str(acc) + \" error rate = \" + str(1-acc))"
   ]
  }
 ]
}